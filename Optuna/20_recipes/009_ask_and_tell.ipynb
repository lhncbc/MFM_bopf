{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Ask-and-Tell Interface\n",
    "\n",
    "Optuna has an `Ask-and-Tell` interface, which provides a more flexible interface for hyperparameter optimization.\n",
    "This tutorial explains three use-cases when the ask-and-tell interface is beneficial:\n",
    "\n",
    "- `Apply-optuna-to-an-existing-optimization-problem-with-minimum-modifications`\n",
    "- `Define-and-Run`\n",
    "- `Batch-Optimization`\n",
    "\n",
    "\n",
    "## Apply Optuna to an existing optimization problem with minimum modifications\n",
    "\n",
    "Let's consider the traditional supervised classification problem; you aim to maximize the validation accuracy.\n",
    "To do so, you train `LogisticRegression` as a simple model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "X, y = make_classification(n_features=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "C = 0.01\n",
    "clf = LogisticRegression(C=C)\n",
    "clf.fit(X_train, y_train)\n",
    "val_accuracy = clf.score(X_test, y_test)  # the objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you try to optimize hyperparameters ``C`` and ``solver`` of the classifier by using optuna.\n",
    "When you introduce optuna naively, you define an ``objective`` function\n",
    "such that it takes ``trial`` and calls ``suggest_*`` methods of ``trial`` to sample the hyperparameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    X, y = make_classification(n_features=10)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-7, 10.0)\n",
    "    solver = trial.suggest_categorical(\"solver\", (\"lbfgs\", \"saga\"))\n",
    "\n",
    "    clf = LogisticRegression(C=C, solver=solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    return val_accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface is not flexible enough.\n",
    "For example, if ``objective`` requires additional arguments other than ``trial``,\n",
    "you need to define a class as in\n",
    "`How to define objective functions that have own arguments? <../../faq.html#how-to-define-objective-functions-that-have-own-arguments>`_.\n",
    "The ask-and-tell interface provides a more flexible syntax to optimize hyperparameters.\n",
    "The following example is equivalent to the previous code block.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "n_trials = 10\n",
    "for _ in range(n_trials):\n",
    "    trial = study.ask()  # `trial` is a `Trial` and not a `FrozenTrial`.\n",
    "\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-7, 10.0)\n",
    "    solver = trial.suggest_categorical(\"solver\", (\"lbfgs\", \"saga\"))\n",
    "\n",
    "    clf = LogisticRegression(C=C, solver=solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    study.tell(trial, val_accuracy)  # tell the pair of trial and objective value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference is to use two methods: :func:`optuna.study.Study.ask`\n",
    "and :func:`optuna.study.Study.tell`.\n",
    ":func:`optuna.study.Study.ask` creates a trial that can sample hyperparameters, and\n",
    ":func:`optuna.study.Study.tell` finishes the trial by passing ``trial`` and an objective value.\n",
    "You can apply Optuna's hyperparameter optimization to your original code\n",
    "without an ``objective`` function.\n",
    "\n",
    "If you want to make your optimization faster with a pruner, you need to explicitly pass the state of trial\n",
    "to the argument of :func:`optuna.study.Study.tell` method as follows:\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "   import numpy as np\n",
    "   from sklearn.datasets import load_iris\n",
    "   from sklearn.linear_model import SGDClassifier\n",
    "   from sklearn.model_selection import train_test_split\n",
    "\n",
    "   import optuna\n",
    "\n",
    "\n",
    "   X, y = load_iris(return_X_y=True)\n",
    "   X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "   classes = np.unique(y)\n",
    "   n_train_iter = 100\n",
    "\n",
    "   # define study with hyperband pruner.\n",
    "   study = optuna.create_study(\n",
    "       direction=\"maximize\",\n",
    "       pruner=optuna.pruners.HyperbandPruner(\n",
    "           min_resource=1, max_resource=n_train_iter, reduction_factor=3\n",
    "       ),\n",
    "   )\n",
    "\n",
    "   for _ in range(20):\n",
    "       trial = study.ask()\n",
    "\n",
    "       alpha = trial.suggest_uniform(\"alpha\", 0.0, 1.0)\n",
    "\n",
    "       clf = SGDClassifier(alpha=alpha)\n",
    "       pruned_trial = False\n",
    "\n",
    "       for step in range(n_train_iter):\n",
    "           clf.partial_fit(X_train, y_train, classes=classes)\n",
    "\n",
    "           intermediate_value = clf.score(X_valid, y_valid)\n",
    "           trial.report(intermediate_value, step)\n",
    "\n",
    "           if trial.should_prune():\n",
    "               pruned_trial = True\n",
    "               break\n",
    "\n",
    "       if pruned_trial:\n",
    "           study.tell(trial, state=optuna.trial.TrialState.PRUNED)  # tell the pruned state\n",
    "       else:\n",
    "           score = clf.score(X_valid, y_valid)\n",
    "           study.tell(trial, score)  # tell objective value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>:func:`optuna.study.Study.tell` method can take a trial number rather than the trial object.\n",
    "    ``study.tell(trial.number, y)`` is equivalent to ``study.tell(trial, y)``.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Define-and-Run\n",
    "The ask-and-tell interface supports both `define-by-run` and `define-and-run` APIs.\n",
    "This section shows the example of the `define-and-run` API\n",
    "in addition to the define-by-run example above.\n",
    "\n",
    "Define distributions for the hyperparameters before calling the\n",
    ":func:`optuna.study.Study.ask` method for define-and-run API.\n",
    "For example,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {\n",
    "    \"C\": optuna.distributions.LogUniformDistribution(1e-7, 10.0),\n",
    "    \"solver\": optuna.distributions.CategoricalDistribution((\"lbfgs\", \"saga\")),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass ``distributions`` to :func:`optuna.study.Study.ask` method at each call.\n",
    "The retuned ``trial`` contains the suggested hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "n_trials = 10\n",
    "for _ in range(n_trials):\n",
    "    trial = study.ask(distributions)  # pass the pre-defined distributions.\n",
    "\n",
    "    # two hyperparameters are already sampled from the pre-defined distributions\n",
    "    C = trial.params[\"C\"]\n",
    "    solver = trial.params[\"solver\"]\n",
    "\n",
    "    clf = LogisticRegression(C=C, solver=solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    study.tell(trial, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Batch Optimization\n",
    "The ask-and-tell interface enables us to optimize a batched objective for faster optimization.\n",
    "For example, parallelizable evaluation, operation over vectors, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following objective takes batched hyperparameters ``xs`` and ``ys`` instead of a single\n",
    "pair of hyperparameters ``x`` and ``y`` and calculates the objective over the full vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_objective(xs: np.ndarray, ys: np.ndarray):\n",
    "    return xs ** 2 + ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, the number of pairs of hyperparameters in a batch is $10$,\n",
    "and ``batched_objective`` is evaluated three times.\n",
    "Thus, the number of trials is $30$.\n",
    "Note that you need to store either ``trial_ids`` or ``trial`` to call\n",
    ":func:`optuna.study.Study.tell` method after the batched evaluations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "study = optuna.create_study(sampler=optuna.samplers.CmaEsSampler())\n",
    "\n",
    "for _ in range(3):\n",
    "\n",
    "    # create batch\n",
    "    trial_ids = []\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    for _ in range(batch_size):\n",
    "        trial = study.ask()\n",
    "        trial_ids.append(trial.number)\n",
    "        x_batch.append(trial.suggest_float(\"x\", -10, 10))\n",
    "        y_batch.append(trial.suggest_float(\"y\", -10, 10))\n",
    "\n",
    "    # evaluate batched objective\n",
    "    x_batch = np.array(x_batch)\n",
    "    y_batch = np.array(y_batch)\n",
    "    objectives = batched_objective(x_batch, y_batch)\n",
    "\n",
    "    # finish all trials in the batch\n",
    "    for trial_id, objective in zip(trial_ids, objectives):\n",
    "        study.tell(trial_id, objective)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
