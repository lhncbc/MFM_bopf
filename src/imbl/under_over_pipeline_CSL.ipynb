{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, recall_score, \\\n",
    "                            classification_report, roc_auc_score, precision_score, \\\n",
    "                            f1_score, matthews_corrcoef, average_precision_score, \\\n",
    "                            precision_recall_curve\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/csl/CSL_tl_PI.csv', index_col=0)\n",
    "X = df.drop('trans_loss', axis=1, inplace=False)\n",
    "y = df['trans_loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185413, 192)\n",
      "(185413,)\n",
      "Counter({0: 175069, 1: 10344})\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 s, sys: 150 ms, total: 20.7 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(solver='liblinear', C=0.1) # \n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43716    52]\n",
      " [ 2535    51]]\n",
      "Accuracy = 0.9441903611338828\n",
      "Balanced Accuracy = 0.5092667475543904\n",
      "Recall = 0.019721577726218097\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     43768\n",
      "           1       0.50      0.02      0.04      2586\n",
      "\n",
      "    accuracy                           0.94     46354\n",
      "   macro avg       0.72      0.51      0.50     46354\n",
      "weighted avg       0.92      0.94      0.92     46354\n",
      "\n",
      "ROC_AUC = 0.5092667475543904\n",
      "MCC = 0.09033806064448234\n",
      "Average precision/PR_AUC: 0.20\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Balanced Accuracy = {balanced_accuracy_score(y_test, y_pred)}')\n",
    "print(f'Recall = {recall_score(y_test, y_pred)}')\n",
    "print(f'\\nClassification Report:\\n {classification_report(y_test, y_pred)}')\n",
    "print(f'ROC_AUC = {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'MCC = {matthews_corrcoef(y_test, y_pred)}')\n",
    "probs = lr.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, probs, pos_label=1)\n",
    "y_score = lr.decision_function(X_test)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print('Average precision/PR_AUC: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 131301, 1: 131301})\n",
      "(262602, 192)\n"
     ]
    }
   ],
   "source": [
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "# summarize class distribution\n",
    "print(Counter(y_over))\n",
    "print(X_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.7 s, sys: 195 ms, total: 42.9 s\n",
      "Wall time: 42.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(solver='liblinear', C=0.1) # \n",
    "lr.fit(X_over, y_over)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29262 14506]\n",
      " [  438  2148]]\n",
      "Accuracy = 0.6776114251197307\n",
      "Balanced Accuracy = 0.7495985476681308\n",
      "Recall = 0.8306264501160093\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80     43768\n",
      "           1       0.13      0.83      0.22      2586\n",
      "\n",
      "    accuracy                           0.68     46354\n",
      "   macro avg       0.56      0.75      0.51     46354\n",
      "weighted avg       0.94      0.68      0.76     46354\n",
      "\n",
      "ROC_AUC = 0.7495985476681308\n",
      "MCC = 0.23879605950463956\n",
      "Average precision/PR_AUC: 0.19\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Balanced Accuracy = {balanced_accuracy_score(y_test, y_pred)}')\n",
    "print(f'Recall = {recall_score(y_test, y_pred)}')\n",
    "print(f'\\nClassification Report:\\n {classification_report(y_test, y_pred)}')\n",
    "print(f'ROC_AUC = {roc_auc_score(y_test, y_pred)}')\n",
    "print(f'MCC = {matthews_corrcoef(y_test, y_pred)}')\n",
    "probs = lr.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, probs, pos_label=1)\n",
    "y_score = lr.decision_function(X_test)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print('Average precision/PR_AUC: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1060214  0.09959869 0.07374727 0.10746776 0.09313987 0.12546632\n",
      " 0.09630177 0.07834359 0.07512109 0.10351929 0.12281503 0.08927002\n",
      " 0.09844225 0.1176752  0.116693   0.10653179 0.09794739 0.09616889\n",
      " 0.10292896 0.08240991 0.10107292 0.09223481 0.10747739 0.08606741\n",
      " 0.09800936 0.10007753 0.09555314 0.11221685 0.09505216 0.12506478]\n",
      "F-measure: 0.100\n",
      "CPU times: user 3.41 s, sys: 732 ms, total: 4.15 s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "#from imblearn.under_sampling import RandomUnderSampler # MWB\n",
    "# define pipeline\n",
    "steps = [('over', RandomOverSampler()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "def my_mcc(y_true,y_pred):\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    return mcc\n",
    "\n",
    "my_scorer = make_scorer(my_mcc, greater_is_better=True)\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, scoring=my_scorer, cv=cv, n_jobs=-1)\n",
    "print(scores)\n",
    "score = np.mean(scores)\n",
    "print('MCC: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25001179 0.25662432 0.25458582 0.2581572  0.25465168]\n",
      "MCC: 0.255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import precision_score\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=40)\n",
    "over = RandomOverSampler(sampling_strategy=0.07)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "\n",
    "# define pipeline\n",
    "pipeline = Pipeline(steps=[('o', over), ('u', under), ('m', model)])\n",
    "#pipeline = Pipeline(steps=[('u', under), ('m', model)])\n",
    "scores = cross_val_score(pipeline, X, y, scoring=my_scorer, cv=cv, n_jobs=-1)\n",
    "print(scores)\n",
    "score = np.mean(scores)\n",
    "print('MCC: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([7.86820555, 7.96624255, 7.64433503, 7.98609805, 8.01649499,\n",
      "       7.79712152, 7.62201571, 7.64926338, 7.54900122, 7.96243   ,\n",
      "       7.80578208, 7.93241429, 7.61831403, 7.82596898, 8.11925149,\n",
      "       7.62759042, 7.2636919 , 7.56525493, 7.63514376, 7.26644588,\n",
      "       7.52141929, 7.6420083 , 7.61117697, 7.34517503, 5.32696557,\n",
      "       6.94490027, 6.58053899, 5.06340718, 6.99250984, 6.3908267 ]), 'score_time': array([0.82484603, 0.85238099, 0.84089088, 0.88418031, 0.8258698 ,\n",
      "       0.82290244, 0.84870172, 0.8121717 , 0.78223372, 0.80407786,\n",
      "       0.79156661, 0.77422667, 0.89169025, 0.8223393 , 0.88192916,\n",
      "       0.78949738, 0.82191157, 0.79568744, 0.83147097, 0.85289145,\n",
      "       0.81077909, 0.84969711, 0.7840755 , 0.83111954, 0.6190033 ,\n",
      "       0.70042515, 0.49695635, 0.51940942, 0.48555779, 0.54561663]), 'test_prec': array([0.13518654, 0.13160198, 0.13111207, 0.13217065, 0.13017837,\n",
      "       0.1333234 , 0.13155582, 0.13168664, 0.13160607, 0.13111888,\n",
      "       0.13445378, 0.1318602 , 0.13384321, 0.13005196, 0.13290763,\n",
      "       0.13251224, 0.13175231, 0.13339158, 0.13375796, 0.13054907,\n",
      "       0.13475904, 0.13234654, 0.13322771, 0.13217973, 0.13486794,\n",
      "       0.13241279, 0.13399941, 0.1322805 , 0.13094027, 0.13311925]), 'test_mcc': array([0.264161  , 0.25278594, 0.25345302, 0.25745764, 0.25114852,\n",
      "       0.25461271, 0.25210224, 0.25300605, 0.25130516, 0.25145957,\n",
      "       0.26014753, 0.25570608, 0.25860784, 0.25002997, 0.25386901,\n",
      "       0.25271502, 0.25290238, 0.25943748, 0.25717646, 0.24909499,\n",
      "       0.26249467, 0.25636371, 0.26087499, 0.25568257, 0.26162711,\n",
      "       0.25655135, 0.25962766, 0.25675999, 0.25165147, 0.25775197])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import precision_score\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=40)\n",
    "over = RandomOverSampler(sampling_strategy=0.07)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scoring = {'prec':'precision', 'mcc': my_scorer}\n",
    "# define pipeline\n",
    "#pipeline = Pipeline(steps=[('o', over), ('u', under), ('m', model)])\n",
    "pipeline = Pipeline(steps=[('u', under), ('m', model)])\n",
    "scores = cross_validate(pipeline, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1.34051442, 1.36084175]), 'score_time': array([1.05538368, 1.03332877]), 'test_prec': array([0.13266837, 0.13456205]), 'test_mcc': array([0.25483995, 0.25835715])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import precision_score\n",
    "#model = RandomForestClassifier(n_estimators=100, max_depth=40)\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=11, \n",
    "                                   min_samples_split=900, min_samples_leaf=50,\n",
    "                                   subsample=0.85, learning_rate=0.1, max_features=12)\n",
    "over = RandomOverSampler(sampling_strategy=0.07)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "\n",
    "scoring = {'prec':'precision', 'mcc': my_scorer}\n",
    "# define pipeline\n",
    "#pipeline = Pipeline(steps=[('o', over), ('u', under), ('m', model)])\n",
    "pipeline = Pipeline(steps=[('u', under), ('m', model)])\n",
    "scores = cross_validate(pipeline, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1.24604654, 1.00842834]), 'score_time': array([0.2119596 , 0.23433828]), 'test_prec': array([0.12310488, 0.12345714]), 'test_mcc': array([0.22958409, 0.22876001])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import precision_score\n",
    "#model = RandomForestClassifier(n_estimators=100, max_depth=40)\n",
    "model = LogisticRegression()\n",
    "#model = GradientBoostingClassifier(n_estimators=100, max_depth=11, \n",
    "#                                   min_samples_split=900, min_samples_leaf=50,\n",
    "#                                   subsample=0.85, learning_rate=0.1, max_features=12)\n",
    "over = RandomOverSampler(sampling_strategy=0.07)\n",
    "under = RandomUnderSampler(sampling_strategy=1.0)\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "\n",
    "scoring = {'prec':'precision', 'mcc': my_scorer}\n",
    "# define pipeline\n",
    "#pipeline = Pipeline(steps=[('o', over), ('u', under), ('m', model)])\n",
    "pipeline = Pipeline(steps=[('u', under), ('m', model)])\n",
    "scores = cross_validate(pipeline, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
