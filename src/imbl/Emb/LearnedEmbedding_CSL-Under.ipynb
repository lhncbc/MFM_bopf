{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset(filename, cramer_coef, target, var_count, row_count):\n",
    "    # load the dataset as a pandas DataFrame\n",
    "    df = pd.read_csv(filename, header=0, index_col=0, nrows=row_count)\n",
    "    \n",
    "    # split into input (X) and output (y) variables\n",
    "    X = df.drop(target, axis=1, inplace=False)\n",
    "    \n",
    "    # order columns by Cramer coeffs\n",
    "    cramer_df = pd.read_csv(cramer_coef, sep='\\t', header=None)\n",
    "    cols = cramer_df.iloc[:, 0].tolist()\n",
    "    X = X[cols]\n",
    "    \n",
    "    # Reduce # of variables\n",
    "    if var_count < X.shape[1]:\n",
    "        X = X.iloc[:, 0:var_count]\n",
    "        \n",
    "    y = df[target].values\n",
    "    \n",
    "    # reshape target to be a 2d array\n",
    "    #y = y.reshape((len(y), 1))\n",
    "    #X = X.values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def encode_df(df):\n",
    "    df_enc = pd.DataFrame()\n",
    "    for col in df:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[col])\n",
    "        df_enc[col] = le.transform(df[col])\n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def prepare_inputs(X_train, X_test):\n",
    "    X_train_enc, X_test_enc = list(), list()\n",
    "    # label encode each column\n",
    "    for i in range(X_train.shape[1]):\n",
    "        le = LabelEncoder()\n",
    "        #le.fit(X_train[:, i])\n",
    "        # Fix missing field error by fitting both train & test - MWB\n",
    "        both = np.concatenate((X_train[:, i], X_test[:,i]), axis=0)\n",
    "        le.fit(both)  \n",
    "        # encode\n",
    "        train_enc = le.transform(X_train[:, i])\n",
    "        test_enc = le.transform(X_test[:, i])\n",
    "        \n",
    "        X_train_enc.append(train_enc)\n",
    "        X_test_enc.append(test_enc)\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MWB - Not necessary - already [0,1]\n",
    "# prepare target\n",
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 200\n",
    "#np.set_printoptions(threshold=1000)\n",
    "np.set_printoptions(edgeitems=1000, threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.04 s, sys: 1.2 s, total: 6.24 s\n",
      "Wall time: 17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(185413, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# example of learned embedding encoding for a neural network\n",
    "from numpy import unique\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "#from keras.utils import plot_model  MWB - errors\n",
    "#from prettytable import PrettyTable\n",
    "#from tabulate import tabulate\n",
    " \n",
    "# load the dataset\n",
    "X, y = load_dataset('/MFMDatasets/MFM_bopf/data/csl/CSL_tl_PI_binned.csv', \n",
    "                    '/MFMDatasets/MFM_bopf/data/csl/CramerTheil/Cramer_PI_Tl_coeff_ALL.csv',\n",
    "                    'trans_loss', 5, 200000)\n",
    "#                    'trans_loss', 9, 200000)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Encode features using LabelEncoder\n",
    "X_enc_df = encode_df(X)\n",
    "\n",
    "for col in X_enc_df:\n",
    "    print(unique(X_enc_df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129789, 5)\n",
      "(129789,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_enc_df, y, stratify=y, test_size=0.30, random_state=1)\n",
    "\n",
    "X_train_enc = np.array(X_train)\n",
    "X_test_enc = np.array(X_test)\n",
    "y_train_enc = np.array(y_train)\n",
    "y_test_enc = np.array(y_test)\n",
    "print(X_train_enc.shape)\n",
    "print(y_train_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_enc_df, y, stratify=y, test_size=0.30, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under_method = RAND\n",
      "target = None\n",
      "\n",
      "In under_samp(): X.shape = (129789, 5); y.shape = (129789,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stat_mwb import under_samp\n",
    "\n",
    "#X_res, y_res = under_samp(X_train_enc, y_train_enc)\n",
    "X_train, y_train= under_samp(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14482, 5)\n",
      "(14482,)\n"
     ]
    }
   ],
   "source": [
    "X_train_enc = np.array(X_train)\n",
    "X_test_enc = np.array(X_test)\n",
    "y_train_enc = np.array(y_train)\n",
    "y_test_enc = np.array(y_test)\n",
    "print(X_train_enc.shape)\n",
    "print(y_train_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under_method = RAND\n",
      "target = None\n",
      "\n",
      "In under_samp(): X.shape = (14482, 5); y.shape = (14482,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stat_mwb import under_samp\n",
    "\n",
    "#X_res, y_res = under_samp(X_train_enc, y_train_enc)\n",
    "X_train_enc, y_train_enc = under_samp(X_train_enc, y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14482, 5)\n",
      "[7241 7241]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_enc.shape)\n",
    "print(np.bincount(y_train_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14482, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make output 3d\n",
    "y_train_enc = y_train_enc.reshape((len(y_train_enc), 1, 1))\n",
    "y_test_enc = y_test_enc.reshape((len(y_test_enc), 1, 1))\n",
    "# prepare each input head\n",
    "print(y_train_enc.shape)\n",
    "y_train_enc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0 1 2 3 4 5 6 7 9]\n",
      "[0 1]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "for col in range(X_train_enc.shape[1]):\n",
    "    print(unique(X_train_enc[:,col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14482, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_layers = list()\n",
    "em_layers = list()\n",
    "for col in range(X_train_enc.shape[1]):\n",
    "    # calculate the number of unique inputs\n",
    "    n_labels = len(unique(X_train_enc[:, col]))\n",
    "    # define input layer\n",
    "    in_layer = Input(shape=(1,))\n",
    "    # define embedding layer\n",
    "    em_layer = Embedding(n_labels+1, 10)(in_layer)  # MWB - Embedding docs say to use this\n",
    "    #em_layer = Embedding(n_labels, 10)(in_layer)\n",
    "    # store layers\n",
    "    in_layers.append(in_layer)\n",
    "    em_layers.append(em_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14482, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose input data to lists\n",
    "X_train_encl = []\n",
    "X_test_encl = []\n",
    "for col in range(X_train_enc.shape[1]):\n",
    "    X_train_encl.append(X_train_enc[..., [col]])\n",
    "    X_test_encl.append(X_test_enc[..., [col]])\n",
    "X_train_encl[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[0 1 2 3 4 5 6 7 9]\n",
      "[0 1]\n",
      "[0 1 2 3 4 5]\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "for col in range(X_train_enc.shape[1]):\n",
    "    print(unique(X_train_enc[:,col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(in_layers))\n",
    "print(len(em_layers))\n",
    "print(type(em_layers))\n",
    "print(type(X_train_encl))\n",
    "print(len(X_train_encl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "906/906 - 8s - loss: 0.5678 - accuracy: 0.7079 - precision: 0.6679 - recall: 0.8272 - auc: 0.7600\n",
      "Epoch 2/20\n",
      "906/906 - 4s - loss: 0.5410 - accuracy: 0.7214 - precision: 0.6592 - recall: 0.9166 - auc: 0.7841\n",
      "Epoch 3/20\n",
      "906/906 - 5s - loss: 0.5393 - accuracy: 0.7203 - precision: 0.6588 - recall: 0.9140 - auc: 0.7858\n",
      "Epoch 4/20\n",
      "906/906 - 5s - loss: 0.5383 - accuracy: 0.7208 - precision: 0.6588 - recall: 0.9156 - auc: 0.7871\n",
      "Epoch 5/20\n",
      "906/906 - 4s - loss: 0.5384 - accuracy: 0.7210 - precision: 0.6586 - recall: 0.9177 - auc: 0.7867\n",
      "Epoch 6/20\n",
      "906/906 - 4s - loss: 0.5385 - accuracy: 0.7217 - precision: 0.6592 - recall: 0.9180 - auc: 0.7861\n",
      "Epoch 7/20\n",
      "906/906 - 4s - loss: 0.5381 - accuracy: 0.7211 - precision: 0.6587 - recall: 0.9177 - auc: 0.7874\n",
      "Epoch 8/20\n",
      "906/906 - 4s - loss: 0.5378 - accuracy: 0.7210 - precision: 0.6592 - recall: 0.9152 - auc: 0.7877\n",
      "Epoch 9/20\n",
      "906/906 - 4s - loss: 0.5379 - accuracy: 0.7212 - precision: 0.6590 - recall: 0.9169 - auc: 0.7880\n",
      "Epoch 10/20\n",
      "906/906 - 3s - loss: 0.5380 - accuracy: 0.7219 - precision: 0.6591 - recall: 0.9192 - auc: 0.7877\n",
      "Epoch 11/20\n",
      "906/906 - 3s - loss: 0.5379 - accuracy: 0.7214 - precision: 0.6591 - recall: 0.9173 - auc: 0.7878\n",
      "Epoch 12/20\n",
      "906/906 - 3s - loss: 0.5375 - accuracy: 0.7212 - precision: 0.6588 - recall: 0.9177 - auc: 0.7875\n",
      "Epoch 13/20\n",
      "906/906 - 5s - loss: 0.5376 - accuracy: 0.7210 - precision: 0.6589 - recall: 0.9162 - auc: 0.7889\n",
      "Epoch 14/20\n",
      "906/906 - 4s - loss: 0.5373 - accuracy: 0.7210 - precision: 0.6589 - recall: 0.9162 - auc: 0.7893\n",
      "Epoch 15/20\n",
      "906/906 - 4s - loss: 0.5375 - accuracy: 0.7220 - precision: 0.6596 - recall: 0.9173 - auc: 0.7886\n",
      "Epoch 16/20\n",
      "906/906 - 4s - loss: 0.5377 - accuracy: 0.7214 - precision: 0.6592 - recall: 0.9169 - auc: 0.7876\n",
      "Epoch 17/20\n",
      "906/906 - 4s - loss: 0.5373 - accuracy: 0.7219 - precision: 0.6594 - recall: 0.9178 - auc: 0.7882\n",
      "Epoch 18/20\n",
      "906/906 - 4s - loss: 0.5371 - accuracy: 0.7216 - precision: 0.6593 - recall: 0.9170 - auc: 0.7894\n",
      "Epoch 19/20\n",
      "906/906 - 4s - loss: 0.5370 - accuracy: 0.7217 - precision: 0.6597 - recall: 0.9156 - auc: 0.7896\n",
      "Epoch 20/20\n",
      "906/906 - 3s - loss: 0.5367 - accuracy: 0.7216 - precision: 0.6592 - recall: 0.9176 - auc: 0.7897\n",
      "Accuracy: 0.5531425476074219; Prec: 0.10404455661773682; Recall: 0.9210441708564758, AUC: 0.7919477224349976\n",
      "CPU times: user 3min 50s, sys: 7min 15s, total: 11min 6s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# concat all embeddings\n",
    "merge = concatenate(em_layers)\n",
    "dense = Dense(10, activation='relu', kernel_initializer='he_normal')(merge)\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "model = Model(inputs=in_layers, outputs=output)\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', sample_weight_mode='temporal', \n",
    "              metrics=['accuracy','Precision','Recall','AUC'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "# plot graph: MWB - Requires pydot and graphviz (which wants python 3.9)\n",
    "#plot_model(model, show_shapes=True, to_file='embeddings.png')\n",
    "\n",
    "#weights = {0:0.51, 1:18.0}\n",
    "#weights = {0:1, 1:36}\n",
    "#weights = np.zeros((10, 2))\n",
    "#weights[:,0] = 0.51\n",
    "#weights[:,1] = 18.0 \n",
    "#print(type(weights))\n",
    "#print(weights)\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train_encl, y_train_enc, epochs=20, batch_size=16, verbose=2) \n",
    "#model.fit(X_train_enc, y_train_enc, epochs=20, batch_size=16, verbose=2) \n",
    "#model.fit(X_train_enc, y_train_enc, epochs=20, batch_size=16, verbose=2, \n",
    "#          class_weight=weights)\n",
    "# evaluate the keras model\n",
    "_, accuracy, prec, recall, auc = model.evaluate(X_test_encl, y_test_enc, verbose=0)\n",
    "#_, accuracy, prec, recall, auc = model.evaluate(X_test_enc, y_test_enc, verbose=0)\n",
    "#print('Accuracy: %.2f' % (accuracy*100))\n",
    "print(f'Accuracy: {accuracy}; Prec: {prec}; Recall: {recall}, AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
