{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, recall_score, \\\n",
    "                            classification_report, roc_auc_score, precision_score, \\\n",
    "                            f1_score, matthews_corrcoef, average_precision_score, \\\n",
    "                            precision_recall_curve, auc, roc_curve\n",
    "from collections import Counter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(y_test, y_pred, X_test, clf):\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    prob1 = probs[:, 1]\n",
    "    stats_s = pd.Series(dtype='float')\n",
    "    stats_s['recall'] = recall_score(y_test, y_pred)\n",
    "    stats_s['prec'] = precision_score(y_test, y_pred)\n",
    "    stats_s['MCC'] = matthews_corrcoef(y_test, y_pred)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, prob1, pos_label=1)\n",
    "    stats_s['PR_AUC'] = auc(recall, precision)\n",
    "    stats_s['avg_prec'] = average_precision_score(y_test, prob1)\n",
    "    stats_s['roc_auc'] = roc_auc_score(y_test, prob1)\n",
    "    \n",
    "    return stats_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "def sample_data(X, y, samp_type, samp_strat, seed=0):\n",
    "    if samp_type == 'over':\n",
    "        sampler = RandomOverSampler(sampling_strategy=samp_strat, random_state=seed)\n",
    "    elif samp_type == 'under':\n",
    "        sampler = RandomUnderSampler(sampling_strategy=samp_strat, random_state=seed)\n",
    "    else:\n",
    "        print(\"Invalid 'samp_type'\")\n",
    "        \n",
    "    # fit and apply the transform\n",
    "    X_res, y_res = sampler.fit_resample(X, y)\n",
    "    # summarize class distribution\n",
    "    #print(Counter(y_res))\n",
    "    #print(X_res.shape)\n",
    "    \n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapped  random statistics runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "# def bootstrap_stat(X, y, clf, nsamples=100, test_size=0.3, sample_weights=False, under=False, samp_strat=1.0):\n",
    "#     stats_df = pd.DataFrame()\n",
    "#     feat_imps_df = pd.DataFrame()\n",
    "#     for seed in range(nsamples):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=seed)\n",
    "#         #print(f'In bstrap(): y_train.shape = {y_train.shape}; X_train.shape = {X_train.shape}')\n",
    "#         #print(f'In bstrap(): np.bincount(y_train) = {np.bincount(y_train)}')\n",
    "\n",
    "#         if under:\n",
    "#             # Undersample the training data\n",
    "#             #print('Undersampling')\n",
    "#             X_res, y_res = sample_data(X_train, y_train, \"under\", samp_strat=samp_strat, seed=seed)\n",
    "#         else:\n",
    "#             #print('No Undersampling')\n",
    "#             X_res, y_res = X_train, y_train # Not subsampled; use with class_weight='balanced' or sample_weights\n",
    "            \n",
    "#         if sample_weights:\n",
    "#             weights = class_weight.compute_sample_weight('balanced', y=y_res)\n",
    "#             #print(f'np.unique(weights): {np.unique(weights)}')\n",
    "#             clf.fit(X_res, y_res, sample_weight=weights)\n",
    "#         else:\n",
    "#             clf.fit(X_res, y_res)\n",
    "            \n",
    "#         y_pred = clf.predict(X_test)\n",
    "\n",
    "#         stats_s = calc_stats(y_test, y_pred, X_test, clf)\n",
    "#         if stats_df.empty:\n",
    "#             stats_df = pd.DataFrame(stats_s)\n",
    "#             stats_df = stats_df.T\n",
    "#         else:\n",
    "#             stats_df = stats_df.append(stats_s, ignore_index=True)\n",
    "            \n",
    "#         if feat_imps_df.empty:\n",
    "#             feat_imps_df = pd.DataFrame(data=clf.feature_importances_, index=X_test.columns.values, columns=[seed])\n",
    "#         else:\n",
    "#             temp_df = pd.DataFrame(data=clf.feature_importances_, index=X_test.columns.values, columns=[seed])\n",
    "#             feat_imps_df = feat_imps_df.merge(temp_df, left_index=True, right_index=True, how=\"left\")\n",
    "        \n",
    "#     return stats_df, feat_imps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.read_csv('../../data/csl/CramerTheil/Cramer_PI_Tl_coeff_Union50.csv', index_col=0, header=None, delimiter='\\t')\n",
    "#corr_df = pd.read_csv('../../data/csl/CramerTheil/Cramer_PI_noDelmode.csv', index_col=0, header=None, delimiter='\\t')\n",
    "corr_vars = list(corr_df.index.values)\n",
    "len(corr_vars)\n",
    "df = pd.read_csv('../../data/csl/CSL_tl_PI.csv', index_col=0)\n",
    "#df = pd.read_csv('../../data/csl/CSL_tl_PI_Freq.csv', index_col=0)\n",
    "X = df.drop('trans_loss', axis=1, inplace=False)\n",
    "X = X[corr_vars]\n",
    "y = df['trans_loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 11, 'max_features': 12, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 50, 'min_samples_split': 900, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 70, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 7, 'subsample': 0.9, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "CPU times: user 55.4 s, sys: 1.22 s, total: 56.6 s\n",
      "Wall time: 56.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "recall      0.876532\n",
       "prec        0.134697\n",
       "MCC         0.259562\n",
       "PR_AUC      0.209446\n",
       "avg_prec    0.209740\n",
       "roc_auc     0.832368\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from mwb_bootstrap import bootstrap_stat\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=70, criterion=\"friedman_mse\",max_depth=11, min_samples_leaf=50,\n",
    "                                     min_samples_split=900,max_leaf_nodes=None,max_features=12,subsample=0.9,\n",
    "                                     learning_rate=0.1,random_state=7)\n",
    "#clf = GradientBoostingClassifier(n_estimators=70, criterion=\"friedman_mse\",max_depth=11, min_samples_leaf=50,\n",
    "#                                     min_samples_split=900,max_leaf_nodes=None,max_features=None,subsample=0.9,\n",
    "#                                     learning_rate=0.1,random_state=7)\n",
    "print(clf.get_params())\n",
    "#stats_df = bootstrap_stat(X, y, clf, nsamples=100, under=True)\n",
    "stats_df, feats_df, _ = bootstrap_stat(X, y, clf, nsamples=25, under=True)\n",
    "#stats_df, feats_df = bootstrap_stat(X, y, clf, sample_weights=True, nsamples=20, under=False)\n",
    "stats_df.loc['mean'] = stats_df.mean()\n",
    "stats_df.loc['mean',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Delmode</th>\n",
       "      <td>0.210295</td>\n",
       "      <td>0.247370</td>\n",
       "      <td>0.238563</td>\n",
       "      <td>0.240012</td>\n",
       "      <td>0.270936</td>\n",
       "      <td>0.221043</td>\n",
       "      <td>0.259313</td>\n",
       "      <td>0.248807</td>\n",
       "      <td>0.253288</td>\n",
       "      <td>0.226934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240074</td>\n",
       "      <td>0.221149</td>\n",
       "      <td>0.235556</td>\n",
       "      <td>0.238446</td>\n",
       "      <td>0.280697</td>\n",
       "      <td>0.241586</td>\n",
       "      <td>0.216838</td>\n",
       "      <td>0.247658</td>\n",
       "      <td>0.286112</td>\n",
       "      <td>0.238933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inoxy_incrdose</th>\n",
       "      <td>0.065815</td>\n",
       "      <td>0.060375</td>\n",
       "      <td>0.097570</td>\n",
       "      <td>0.109158</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>0.066472</td>\n",
       "      <td>0.075514</td>\n",
       "      <td>0.087013</td>\n",
       "      <td>0.044786</td>\n",
       "      <td>0.113235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062870</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>0.098086</td>\n",
       "      <td>0.053054</td>\n",
       "      <td>0.107810</td>\n",
       "      <td>0.053290</td>\n",
       "      <td>0.051879</td>\n",
       "      <td>0.047302</td>\n",
       "      <td>0.094097</td>\n",
       "      <td>0.072889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intratocolytix</th>\n",
       "      <td>0.060062</td>\n",
       "      <td>0.067275</td>\n",
       "      <td>0.076105</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>0.067885</td>\n",
       "      <td>0.064964</td>\n",
       "      <td>0.061990</td>\n",
       "      <td>0.071126</td>\n",
       "      <td>0.080447</td>\n",
       "      <td>0.051242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069849</td>\n",
       "      <td>0.069356</td>\n",
       "      <td>0.071938</td>\n",
       "      <td>0.082581</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.071966</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.073419</td>\n",
       "      <td>0.031802</td>\n",
       "      <td>0.064847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMControl</th>\n",
       "      <td>0.053555</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.054583</td>\n",
       "      <td>0.041525</td>\n",
       "      <td>0.041666</td>\n",
       "      <td>0.029243</td>\n",
       "      <td>0.042917</td>\n",
       "      <td>0.024481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055830</td>\n",
       "      <td>0.039801</td>\n",
       "      <td>0.035989</td>\n",
       "      <td>0.026373</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>0.040720</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.026119</td>\n",
       "      <td>0.032194</td>\n",
       "      <td>0.036440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.033805</td>\n",
       "      <td>0.026341</td>\n",
       "      <td>0.023657</td>\n",
       "      <td>0.031921</td>\n",
       "      <td>0.019228</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.029712</td>\n",
       "      <td>0.040462</td>\n",
       "      <td>0.056557</td>\n",
       "      <td>0.038946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.061116</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.058001</td>\n",
       "      <td>0.019093</td>\n",
       "      <td>0.047316</td>\n",
       "      <td>0.045948</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.032786</td>\n",
       "      <td>0.035939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAmethod</th>\n",
       "      <td>0.036443</td>\n",
       "      <td>0.021462</td>\n",
       "      <td>0.030670</td>\n",
       "      <td>0.023587</td>\n",
       "      <td>0.049090</td>\n",
       "      <td>0.026510</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.048416</td>\n",
       "      <td>0.029601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038715</td>\n",
       "      <td>0.045823</td>\n",
       "      <td>0.036965</td>\n",
       "      <td>0.043439</td>\n",
       "      <td>0.028247</td>\n",
       "      <td>0.043026</td>\n",
       "      <td>0.042478</td>\n",
       "      <td>0.031054</td>\n",
       "      <td>0.026903</td>\n",
       "      <td>0.034168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insurance</th>\n",
       "      <td>0.037202</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>0.030513</td>\n",
       "      <td>0.032305</td>\n",
       "      <td>0.022781</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.043211</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.036822</td>\n",
       "      <td>0.016613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027123</td>\n",
       "      <td>0.033815</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.025050</td>\n",
       "      <td>0.028749</td>\n",
       "      <td>0.026930</td>\n",
       "      <td>0.032170</td>\n",
       "      <td>0.040846</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.028446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROMmeth</th>\n",
       "      <td>0.031776</td>\n",
       "      <td>0.030824</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.033941</td>\n",
       "      <td>0.017896</td>\n",
       "      <td>0.027663</td>\n",
       "      <td>0.025308</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>0.028048</td>\n",
       "      <td>0.029647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.023505</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>0.032602</td>\n",
       "      <td>0.028873</td>\n",
       "      <td>0.023537</td>\n",
       "      <td>0.018213</td>\n",
       "      <td>0.027148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrialLabor</th>\n",
       "      <td>0.021259</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.029964</td>\n",
       "      <td>0.028945</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.032666</td>\n",
       "      <td>0.026718</td>\n",
       "      <td>0.030881</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.023388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018278</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>0.029536</td>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>0.029456</td>\n",
       "      <td>0.030021</td>\n",
       "      <td>0.020464</td>\n",
       "      <td>0.026629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hxanemia</th>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.027212</td>\n",
       "      <td>0.018918</td>\n",
       "      <td>0.018849</td>\n",
       "      <td>0.020425</td>\n",
       "      <td>0.028447</td>\n",
       "      <td>0.022862</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.034217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023175</td>\n",
       "      <td>0.021922</td>\n",
       "      <td>0.020906</td>\n",
       "      <td>0.026984</td>\n",
       "      <td>0.024241</td>\n",
       "      <td>0.024931</td>\n",
       "      <td>0.027195</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.020251</td>\n",
       "      <td>0.024150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analgesia</th>\n",
       "      <td>0.020569</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.037348</td>\n",
       "      <td>0.024618</td>\n",
       "      <td>0.019217</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.042794</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>0.018729</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>0.019492</td>\n",
       "      <td>0.020170</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.022412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momrace_new</th>\n",
       "      <td>0.026557</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>0.016149</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>0.015380</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.025241</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>0.027124</td>\n",
       "      <td>0.025782</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.026050</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.016199</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.022307</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lac_Min</th>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>0.021270</td>\n",
       "      <td>0.017069</td>\n",
       "      <td>0.039697</td>\n",
       "      <td>0.018384</td>\n",
       "      <td>0.016090</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033469</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.023110</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.011447</td>\n",
       "      <td>0.010234</td>\n",
       "      <td>0.020759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS_FTP</th>\n",
       "      <td>0.026528</td>\n",
       "      <td>0.023969</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.017858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>0.026458</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.016626</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.026258</td>\n",
       "      <td>0.026553</td>\n",
       "      <td>0.028027</td>\n",
       "      <td>0.019561</td>\n",
       "      <td>0.020198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HxnumCS</th>\n",
       "      <td>0.014459</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.020963</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025782</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.032794</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>0.022172</td>\n",
       "      <td>0.036967</td>\n",
       "      <td>0.024447</td>\n",
       "      <td>0.017611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BESTGA</th>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.016770</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014910</td>\n",
       "      <td>0.017821</td>\n",
       "      <td>0.016768</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>0.017092</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0.016189</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>0.016024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdmBishop</th>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.028487</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>0.027990</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>0.030314</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>0.027408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.026779</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.030490</td>\n",
       "      <td>0.015145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delfetalpos</th>\n",
       "      <td>0.015478</td>\n",
       "      <td>0.016852</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024532</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.017177</td>\n",
       "      <td>0.011357</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.014577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admcontract</th>\n",
       "      <td>0.018379</td>\n",
       "      <td>0.009405</td>\n",
       "      <td>0.016587</td>\n",
       "      <td>0.018557</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.024462</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013222</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0.018603</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.014190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admconsistency</th>\n",
       "      <td>0.011298</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>0.031438</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>0.023635</td>\n",
       "      <td>0.013955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HospElectInd</th>\n",
       "      <td>0.014976</td>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>0.012672</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.013478</td>\n",
       "      <td>0.018246</td>\n",
       "      <td>0.012962</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.012506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HosEpiNurse</th>\n",
       "      <td>0.011508</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>0.014078</td>\n",
       "      <td>0.007411</td>\n",
       "      <td>0.011975</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.020025</td>\n",
       "      <td>0.010786</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.017485</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.006973</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.017713</td>\n",
       "      <td>0.012281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdmDBP</th>\n",
       "      <td>0.011278</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013204</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.014644</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.009548</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.012176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdmSBP</th>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>0.012181</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>0.013906</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>0.012126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hostype</th>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.018751</td>\n",
       "      <td>0.019911</td>\n",
       "      <td>0.012425</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.015842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.007090</td>\n",
       "      <td>0.011590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dilat_lst</th>\n",
       "      <td>0.012413</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.017306</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.009962</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.010059</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.009646</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.011085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HospElectCS</th>\n",
       "      <td>0.016010</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>0.012339</td>\n",
       "      <td>0.018080</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012861</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.007746</td>\n",
       "      <td>0.010939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS_UScar</th>\n",
       "      <td>0.010489</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.015561</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>0.008574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012497</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.013973</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.010892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HosEpitype</th>\n",
       "      <td>0.015272</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.012977</td>\n",
       "      <td>0.012409</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.015002</td>\n",
       "      <td>0.014458</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.016872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020585</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.016054</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>0.013858</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>0.010699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admefface</th>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.014047</td>\n",
       "      <td>0.011823</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.009382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1         2         3         4         5  \\\n",
       "Delmode         0.210295  0.247370  0.238563  0.240012  0.270936  0.221043   \n",
       "Inoxy_incrdose  0.065815  0.060375  0.097570  0.109158  0.083446  0.066472   \n",
       "Intratocolytix  0.060062  0.067275  0.076105  0.038851  0.067885  0.064964   \n",
       "DMControl       0.053555  0.032987  0.021429  0.024046  0.054583  0.041525   \n",
       "Education       0.033805  0.026341  0.023657  0.031921  0.019228  0.022004   \n",
       "GAmethod        0.036443  0.021462  0.030670  0.023587  0.049090  0.026510   \n",
       "Insurance       0.037202  0.027860  0.030513  0.032305  0.022781  0.031738   \n",
       "ROMmeth         0.031776  0.030824  0.028500  0.033941  0.017896  0.027663   \n",
       "TrialLabor      0.021259  0.032573  0.029964  0.028945  0.020362  0.032666   \n",
       "Hxanemia        0.022023  0.027212  0.018918  0.018849  0.020425  0.028447   \n",
       "Analgesia       0.020569  0.027601  0.037348  0.024618  0.019217  0.014392   \n",
       "momrace_new     0.026557  0.018141  0.016149  0.014006  0.026941  0.025876   \n",
       "Lac_Min         0.018401  0.019148  0.021168  0.021270  0.017069  0.039697   \n",
       "CS_FTP          0.026528  0.023969  0.027809  0.013738  0.013714  0.023493   \n",
       "HxnumCS         0.014459  0.008290  0.015584  0.013763  0.015682  0.020963   \n",
       "BESTGA          0.014450  0.016770  0.016478  0.016857  0.015024  0.012520   \n",
       "AdmBishop       0.003909  0.028487  0.013240  0.027740  0.007438  0.027990   \n",
       "Delfetalpos     0.015478  0.016852  0.005285  0.010253  0.013546  0.023981   \n",
       "Admcontract     0.018379  0.009405  0.016587  0.018557  0.013680  0.009475   \n",
       "Admconsistency  0.011298  0.006819  0.004912  0.031438  0.005007  0.016908   \n",
       "HospElectInd    0.014976  0.016742  0.015844  0.012233  0.010014  0.013530   \n",
       "HosEpiNurse     0.011508  0.015458  0.005489  0.014078  0.007411  0.011975   \n",
       "AdmDBP          0.011278  0.012899  0.013555  0.011226  0.011034  0.013139   \n",
       "AdmSBP          0.012054  0.009617  0.011991  0.011946  0.010490  0.010639   \n",
       "Hostype         0.005558  0.018751  0.019911  0.012425  0.007353  0.010582   \n",
       "Dilat_lst       0.012413  0.009449  0.010046  0.009649  0.006073  0.016599   \n",
       "HospElectCS     0.016010  0.011464  0.009258  0.006174  0.018338  0.006699   \n",
       "CS_UScar        0.010489  0.014506  0.008621  0.012290  0.012609  0.010288   \n",
       "HosEpitype      0.015272  0.014964  0.012977  0.012409  0.002387  0.014724   \n",
       "Admefface       0.007191  0.008576  0.006997  0.008794  0.009418  0.007656   \n",
       "\n",
       "                       6         7         8         9  ...        16  \\\n",
       "Delmode         0.259313  0.248807  0.253288  0.226934  ...  0.240074   \n",
       "Inoxy_incrdose  0.075514  0.087013  0.044786  0.113235  ...  0.062870   \n",
       "Intratocolytix  0.061990  0.071126  0.080447  0.051242  ...  0.069849   \n",
       "DMControl       0.041666  0.029243  0.042917  0.024481  ...  0.055830   \n",
       "Education       0.029712  0.040462  0.056557  0.038946  ...  0.020289   \n",
       "GAmethod        0.011244  0.027227  0.048416  0.029601  ...  0.038715   \n",
       "Insurance       0.043211  0.019599  0.036822  0.016613  ...  0.027123   \n",
       "ROMmeth         0.025308  0.022317  0.028048  0.029647  ...  0.018460   \n",
       "TrialLabor      0.026718  0.030881  0.018018  0.023388  ...  0.018278   \n",
       "Hxanemia        0.022862  0.029468  0.024357  0.034217  ...  0.023175   \n",
       "Analgesia       0.042794  0.018952  0.018729  0.028666  ...  0.020789   \n",
       "momrace_new     0.015380  0.016299  0.025241  0.017827  ...  0.021752   \n",
       "Lac_Min         0.018384  0.016090  0.027709  0.015509  ...  0.033469   \n",
       "CS_FTP          0.013443  0.011716  0.009782  0.017858  ...  0.021302   \n",
       "HxnumCS         0.012944  0.006693  0.025692  0.006517  ...  0.025782   \n",
       "BESTGA          0.013774  0.015117  0.015274  0.013255  ...  0.014910   \n",
       "AdmBishop       0.013504  0.030314  0.004364  0.027408  ...  0.005708   \n",
       "Delfetalpos     0.018878  0.009812  0.004422  0.011930  ...  0.024532   \n",
       "Admcontract     0.024462  0.010455  0.009833  0.010651  ...  0.013222   \n",
       "Admconsistency  0.011143  0.003026  0.009990  0.019079  ...  0.011537   \n",
       "HospElectInd    0.015057  0.010416  0.012672  0.009145  ...  0.008229   \n",
       "HosEpiNurse     0.007768  0.006631  0.013839  0.005898  ...  0.016388   \n",
       "AdmDBP          0.011811  0.010789  0.011512  0.012786  ...  0.013204   \n",
       "AdmSBP          0.009977  0.012849  0.012843  0.012169  ...  0.016038   \n",
       "Hostype         0.010832  0.019269  0.005626  0.015842  ...  0.004102   \n",
       "Dilat_lst       0.013358  0.003428  0.003183  0.018085  ...  0.014831   \n",
       "HospElectCS     0.012339  0.018080  0.010884  0.012422  ...  0.012861   \n",
       "CS_UScar        0.001607  0.015561  0.008663  0.008574  ...  0.012497   \n",
       "HosEpitype      0.015002  0.014458  0.006850  0.016872  ...  0.020585   \n",
       "Admefface       0.007862  0.012905  0.011612  0.005663  ...  0.008945   \n",
       "\n",
       "                      17        18        19        20        21        22  \\\n",
       "Delmode         0.221149  0.235556  0.238446  0.280697  0.241586  0.216838   \n",
       "Inoxy_incrdose  0.042603  0.098086  0.053054  0.107810  0.053290  0.051879   \n",
       "Intratocolytix  0.069356  0.071938  0.082581  0.063003  0.071966  0.053165   \n",
       "DMControl       0.039801  0.035989  0.026373  0.017163  0.040720  0.048403   \n",
       "Education       0.061116  0.023700  0.058001  0.019093  0.047316  0.045948   \n",
       "GAmethod        0.045823  0.036965  0.043439  0.028247  0.043026  0.042478   \n",
       "Insurance       0.033815  0.024887  0.025050  0.028749  0.026930  0.032170   \n",
       "ROMmeth         0.023505  0.018605  0.020397  0.016615  0.032602  0.028873   \n",
       "TrialLabor      0.029251  0.022489  0.029536  0.016263  0.030835  0.029456   \n",
       "Hxanemia        0.021922  0.020906  0.026984  0.024241  0.024931  0.027195   \n",
       "Analgesia       0.019006  0.020921  0.022272  0.019492  0.020170  0.011518   \n",
       "momrace_new     0.027124  0.025782  0.022816  0.026050  0.023413  0.016199   \n",
       "Lac_Min         0.021832  0.031525  0.016361  0.023110  0.025207  0.014137   \n",
       "CS_FTP          0.026458  0.016897  0.016626  0.005942  0.026258  0.026553   \n",
       "HxnumCS         0.022166  0.015917  0.032794  0.010994  0.010012  0.022172   \n",
       "BESTGA          0.017821  0.016768  0.017212  0.015475  0.017092  0.013921   \n",
       "AdmBishop       0.003580  0.007184  0.002395  0.026779  0.003536  0.005321   \n",
       "Delfetalpos     0.011261  0.019331  0.009534  0.010527  0.019064  0.017177   \n",
       "Admcontract     0.020588  0.009188  0.016017  0.009621  0.011306  0.018939   \n",
       "Admconsistency  0.007047  0.023365  0.006330  0.030865  0.004758  0.018160   \n",
       "HospElectInd    0.012997  0.008415  0.012319  0.009228  0.013478  0.018246   \n",
       "HosEpiNurse     0.020025  0.010786  0.014568  0.017485  0.009106  0.006973   \n",
       "AdmDBP          0.012496  0.012740  0.011439  0.014644  0.013846  0.009548   \n",
       "AdmSBP          0.012181  0.013952  0.014322  0.011686  0.013961  0.013906   \n",
       "Hostype         0.005817  0.010999  0.004624  0.008448  0.003187  0.015940   \n",
       "Dilat_lst       0.017306  0.009125  0.009962  0.014890  0.010059  0.007486   \n",
       "HospElectCS     0.008385  0.008247  0.005622  0.006472  0.013963  0.010478   \n",
       "CS_UScar        0.008354  0.007925  0.013679  0.008379  0.014967  0.013973   \n",
       "HosEpitype      0.002789  0.016054  0.005811  0.013858  0.015063  0.007377   \n",
       "Admefface       0.014012  0.007706  0.012915  0.009188  0.005042  0.014047   \n",
       "\n",
       "                      23        24      mean  \n",
       "Delmode         0.247658  0.286112  0.238933  \n",
       "Inoxy_incrdose  0.047302  0.094097  0.072889  \n",
       "Intratocolytix  0.073419  0.031802  0.064847  \n",
       "DMControl       0.026119  0.032194  0.036440  \n",
       "Education       0.046173  0.032786  0.035939  \n",
       "GAmethod        0.031054  0.026903  0.034168  \n",
       "Insurance       0.040846  0.020097  0.028446  \n",
       "ROMmeth         0.023537  0.018213  0.027148  \n",
       "TrialLabor      0.030021  0.020464  0.026629  \n",
       "Hxanemia        0.018724  0.020251  0.024150  \n",
       "Analgesia       0.015322  0.024069  0.022412  \n",
       "momrace_new     0.015021  0.022307  0.020800  \n",
       "Lac_Min         0.011447  0.010234  0.020759  \n",
       "CS_FTP          0.028027  0.019561  0.020198  \n",
       "HxnumCS         0.036967  0.024447  0.017611  \n",
       "BESTGA          0.016189  0.018471  0.016024  \n",
       "AdmBishop       0.002886  0.030490  0.015145  \n",
       "Delfetalpos     0.011357  0.014498  0.014577  \n",
       "Admcontract     0.018603  0.011783  0.014190  \n",
       "Admconsistency  0.017393  0.023635  0.013955  \n",
       "HospElectInd    0.012962  0.008951  0.012506  \n",
       "HosEpiNurse     0.015206  0.017713  0.012281  \n",
       "AdmDBP          0.013811  0.012345  0.012176  \n",
       "AdmSBP          0.010599  0.011918  0.012126  \n",
       "Hostype         0.008533  0.007090  0.011590  \n",
       "Dilat_lst       0.009646  0.006231  0.011085  \n",
       "HospElectCS     0.010967  0.007746  0.010939  \n",
       "CS_UScar        0.008569  0.010991  0.010892  \n",
       "HosEpitype      0.003234  0.013438  0.010699  \n",
       "Admefface       0.011823  0.005907  0.009382  \n",
       "\n",
       "[30 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df['mean'] = feats_df.mean(axis=1)\n",
    "feats_df.sort_values(by='mean', inplace=True, ascending=False)\n",
    "feats_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.read_csv('../../data/csl/CramerTheil/Cramer_Pre_Tl_coeff_Union50.csv', index_col=0, header=None, delimiter='\\t')\n",
    "#corr_df = pd.read_csv('../../data/csl/CramerTheil/Cramer_PI_noDelmode.csv', index_col=0, header=None, delimiter='\\t')\n",
    "corr_vars = list(corr_df.index.values)\n",
    "len(corr_vars)\n",
    "df = pd.read_csv('../../data/csl/CSL_tl_Pre.csv', index_col=0)\n",
    "#df = pd.read_csv('../../data/csl/CSL_tl_PI.csv', index_col=0)\n",
    "#df = pd.read_csv('../../data/csl/CSL_tl_PI_Freq.csv', index_col=0)\n",
    "X = df.drop('trans_loss', axis=1, inplace=False)\n",
    "X = X[corr_vars]\n",
    "y = df['trans_loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 11, 'max_features': 12, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 50, 'min_samples_split': 900, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 70, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': 7, 'subsample': 0.9, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "CPU times: user 42.4 s, sys: 641 ms, total: 43 s\n",
      "Wall time: 43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "recall      0.793323\n",
       "prec        0.119189\n",
       "MCC         0.212299\n",
       "PR_AUC      0.172064\n",
       "avg_prec    0.172343\n",
       "roc_auc     0.784541\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=70, criterion=\"friedman_mse\",max_depth=11, min_samples_leaf=50,\n",
    "                                     min_samples_split=900,max_leaf_nodes=None,max_features=12,subsample=0.9,\n",
    "                                     learning_rate=0.1,random_state=7)\n",
    "#clf = GradientBoostingClassifier(n_estimators=70, criterion=\"friedman_mse\",max_depth=11, min_samples_leaf=50,\n",
    "#                                     min_samples_split=900,max_leaf_nodes=None,max_features=None,subsample=0.9,\n",
    "#                                     learning_rate=0.1,random_state=7)\n",
    "print(clf.get_params())\n",
    "#stats_df = bootstrap_stat(X, y, clf, nsamples=100, under=True)\n",
    "stats_df, feats_df = bootstrap_stat(X, y, clf, nsamples=25, under=True)\n",
    "#stats_df, feats_df = bootstrap_stat(X, y, clf, sample_weights=True, nsamples=20, under=False)\n",
    "stats_df.loc['mean'] = stats_df.mean()\n",
    "stats_df.loc['mean',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HxnumCS</th>\n",
       "      <td>0.144438</td>\n",
       "      <td>0.115130</td>\n",
       "      <td>0.140736</td>\n",
       "      <td>0.128202</td>\n",
       "      <td>0.116515</td>\n",
       "      <td>0.131698</td>\n",
       "      <td>0.118182</td>\n",
       "      <td>0.124227</td>\n",
       "      <td>0.136038</td>\n",
       "      <td>0.133076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117554</td>\n",
       "      <td>0.118867</td>\n",
       "      <td>0.148099</td>\n",
       "      <td>0.119524</td>\n",
       "      <td>0.131439</td>\n",
       "      <td>0.118440</td>\n",
       "      <td>0.129595</td>\n",
       "      <td>0.129290</td>\n",
       "      <td>0.116968</td>\n",
       "      <td>0.128191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMControl</th>\n",
       "      <td>0.125042</td>\n",
       "      <td>0.107653</td>\n",
       "      <td>0.103942</td>\n",
       "      <td>0.130679</td>\n",
       "      <td>0.119324</td>\n",
       "      <td>0.126415</td>\n",
       "      <td>0.115720</td>\n",
       "      <td>0.107632</td>\n",
       "      <td>0.131351</td>\n",
       "      <td>0.134597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127274</td>\n",
       "      <td>0.127296</td>\n",
       "      <td>0.109678</td>\n",
       "      <td>0.121699</td>\n",
       "      <td>0.117150</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.124563</td>\n",
       "      <td>0.115088</td>\n",
       "      <td>0.120292</td>\n",
       "      <td>0.120303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prelaborCD</th>\n",
       "      <td>0.067423</td>\n",
       "      <td>0.087077</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.093225</td>\n",
       "      <td>0.088969</td>\n",
       "      <td>0.093897</td>\n",
       "      <td>0.078310</td>\n",
       "      <td>0.083945</td>\n",
       "      <td>0.083431</td>\n",
       "      <td>0.083099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.074255</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.083552</td>\n",
       "      <td>0.077906</td>\n",
       "      <td>0.087991</td>\n",
       "      <td>0.078412</td>\n",
       "      <td>0.082201</td>\n",
       "      <td>0.090533</td>\n",
       "      <td>0.085979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hxanemia</th>\n",
       "      <td>0.067046</td>\n",
       "      <td>0.068595</td>\n",
       "      <td>0.058807</td>\n",
       "      <td>0.062237</td>\n",
       "      <td>0.054331</td>\n",
       "      <td>0.069888</td>\n",
       "      <td>0.063974</td>\n",
       "      <td>0.063962</td>\n",
       "      <td>0.071209</td>\n",
       "      <td>0.077653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070108</td>\n",
       "      <td>0.071376</td>\n",
       "      <td>0.055276</td>\n",
       "      <td>0.068422</td>\n",
       "      <td>0.074181</td>\n",
       "      <td>0.061394</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.068863</td>\n",
       "      <td>0.062430</td>\n",
       "      <td>0.067088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insurance</th>\n",
       "      <td>0.060529</td>\n",
       "      <td>0.059656</td>\n",
       "      <td>0.070413</td>\n",
       "      <td>0.078728</td>\n",
       "      <td>0.066129</td>\n",
       "      <td>0.062573</td>\n",
       "      <td>0.077509</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>0.050590</td>\n",
       "      <td>0.053468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062558</td>\n",
       "      <td>0.058432</td>\n",
       "      <td>0.050307</td>\n",
       "      <td>0.065298</td>\n",
       "      <td>0.066693</td>\n",
       "      <td>0.063441</td>\n",
       "      <td>0.068996</td>\n",
       "      <td>0.068237</td>\n",
       "      <td>0.068611</td>\n",
       "      <td>0.062976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.049262</td>\n",
       "      <td>0.053093</td>\n",
       "      <td>0.042419</td>\n",
       "      <td>0.049154</td>\n",
       "      <td>0.048616</td>\n",
       "      <td>0.054972</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>0.045803</td>\n",
       "      <td>0.058301</td>\n",
       "      <td>0.058819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043925</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.046698</td>\n",
       "      <td>0.044227</td>\n",
       "      <td>0.058135</td>\n",
       "      <td>0.059249</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.049971</td>\n",
       "      <td>0.047959</td>\n",
       "      <td>0.049717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antefetdistress</th>\n",
       "      <td>0.047632</td>\n",
       "      <td>0.044712</td>\n",
       "      <td>0.046799</td>\n",
       "      <td>0.044964</td>\n",
       "      <td>0.047622</td>\n",
       "      <td>0.044849</td>\n",
       "      <td>0.038670</td>\n",
       "      <td>0.044961</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.053025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.050658</td>\n",
       "      <td>0.040868</td>\n",
       "      <td>0.054324</td>\n",
       "      <td>0.047956</td>\n",
       "      <td>0.055392</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>0.030850</td>\n",
       "      <td>0.046927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hostype</th>\n",
       "      <td>0.053884</td>\n",
       "      <td>0.043313</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>0.029952</td>\n",
       "      <td>0.043828</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>0.048192</td>\n",
       "      <td>0.047755</td>\n",
       "      <td>0.033990</td>\n",
       "      <td>0.019001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052833</td>\n",
       "      <td>0.047666</td>\n",
       "      <td>0.034587</td>\n",
       "      <td>0.046601</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>0.046966</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>0.044349</td>\n",
       "      <td>0.051476</td>\n",
       "      <td>0.040027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HospElectCS</th>\n",
       "      <td>0.026834</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>0.031235</td>\n",
       "      <td>0.035736</td>\n",
       "      <td>0.032640</td>\n",
       "      <td>0.038108</td>\n",
       "      <td>0.035463</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>0.031204</td>\n",
       "      <td>0.046316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034431</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.034367</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>0.039233</td>\n",
       "      <td>0.044128</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>0.041345</td>\n",
       "      <td>0.036438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momrace_new</th>\n",
       "      <td>0.037350</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.041038</td>\n",
       "      <td>0.028054</td>\n",
       "      <td>0.041135</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.037309</td>\n",
       "      <td>0.033497</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>0.040718</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.033412</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>0.034666</td>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.040519</td>\n",
       "      <td>0.039586</td>\n",
       "      <td>0.035549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HospElectInd</th>\n",
       "      <td>0.028993</td>\n",
       "      <td>0.037837</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.024193</td>\n",
       "      <td>0.022650</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>0.035578</td>\n",
       "      <td>0.033085</td>\n",
       "      <td>0.027113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.023608</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.030053</td>\n",
       "      <td>0.031262</td>\n",
       "      <td>0.028896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Admreason</th>\n",
       "      <td>0.021447</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.022402</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>0.024337</td>\n",
       "      <td>0.026140</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>0.025594</td>\n",
       "      <td>0.021829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030343</td>\n",
       "      <td>0.026714</td>\n",
       "      <td>0.018962</td>\n",
       "      <td>0.027129</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.021328</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>0.035964</td>\n",
       "      <td>0.024608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parity</th>\n",
       "      <td>0.018462</td>\n",
       "      <td>0.021274</td>\n",
       "      <td>0.031779</td>\n",
       "      <td>0.031471</td>\n",
       "      <td>0.022838</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>0.017672</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>0.029499</td>\n",
       "      <td>0.022884</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.018910</td>\n",
       "      <td>0.024037</td>\n",
       "      <td>0.030486</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.022413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS_UScar</th>\n",
       "      <td>0.034134</td>\n",
       "      <td>0.037104</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>0.017637</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.017229</td>\n",
       "      <td>0.016271</td>\n",
       "      <td>0.022857</td>\n",
       "      <td>0.014446</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014917</td>\n",
       "      <td>0.019322</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>0.026559</td>\n",
       "      <td>0.031331</td>\n",
       "      <td>0.027885</td>\n",
       "      <td>0.021044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anteanemia</th>\n",
       "      <td>0.021673</td>\n",
       "      <td>0.015266</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.028574</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.018787</td>\n",
       "      <td>0.028130</td>\n",
       "      <td>0.015171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.018923</td>\n",
       "      <td>0.021443</td>\n",
       "      <td>0.020672</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>0.017734</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.020151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uscar</th>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>0.016607</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.025030</td>\n",
       "      <td>0.020438</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026595</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>0.009844</td>\n",
       "      <td>0.029606</td>\n",
       "      <td>0.025813</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.018740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anteprevia</th>\n",
       "      <td>0.018584</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.015554</td>\n",
       "      <td>0.021331</td>\n",
       "      <td>0.015516</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.015550</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.017287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.015074</td>\n",
       "      <td>0.019875</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.010576</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.013705</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.016704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hxcsection</th>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.010923</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>0.020338</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>0.021196</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.015395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anteabruption</th>\n",
       "      <td>0.012481</td>\n",
       "      <td>0.016693</td>\n",
       "      <td>0.016737</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.012210</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>0.018034</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.015636</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>0.017487</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.010923</td>\n",
       "      <td>0.013718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antesteroid</th>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.013942</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013859</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.015220</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.013446</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.012058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CS_Elect</th>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>0.012774</td>\n",
       "      <td>0.014903</td>\n",
       "      <td>0.016145</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.015362</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.010899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_BMI</th>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.012843</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008192</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>0.008491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PostHBP</th>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.011984</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.007749</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.008193</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.007866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital</th>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.011366</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.010291</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.008326</td>\n",
       "      <td>0.007855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_Gravidity</th>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.009596</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.007391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.007233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ind_HTN</th>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.008532</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.006566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_Age</th>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.008356</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.006193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnteLGA</th>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.005653</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.008878</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preeclampsia</th>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.005035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_diab</th>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>0.005002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5  \\\n",
       "HxnumCS          0.144438  0.115130  0.140736  0.128202  0.116515  0.131698   \n",
       "DMControl        0.125042  0.107653  0.103942  0.130679  0.119324  0.126415   \n",
       "prelaborCD       0.067423  0.087077  0.079900  0.093225  0.088969  0.093897   \n",
       "Hxanemia         0.067046  0.068595  0.058807  0.062237  0.054331  0.069888   \n",
       "Insurance        0.060529  0.059656  0.070413  0.078728  0.066129  0.062573   \n",
       "Education        0.049262  0.053093  0.042419  0.049154  0.048616  0.054972   \n",
       "Antefetdistress  0.047632  0.044712  0.046799  0.044964  0.047622  0.044849   \n",
       "Hostype          0.053884  0.043313  0.046983  0.029952  0.043828  0.039886   \n",
       "HospElectCS      0.026834  0.039626  0.031235  0.035736  0.032640  0.038108   \n",
       "momrace_new      0.037350  0.032900  0.041038  0.028054  0.041135  0.029168   \n",
       "HospElectInd     0.028993  0.037837  0.027972  0.028388  0.024193  0.022650   \n",
       "Admreason        0.021447  0.025507  0.024024  0.022402  0.029908  0.024337   \n",
       "Parity           0.018462  0.021274  0.031779  0.031471  0.022838  0.023627   \n",
       "CS_UScar         0.034134  0.037104  0.015017  0.017637  0.031008  0.017229   \n",
       "Anteanemia       0.021673  0.015266  0.022119  0.028574  0.014592  0.029421   \n",
       "uscar            0.011524  0.020712  0.027063  0.016607  0.017773  0.014728   \n",
       "Anteprevia       0.018584  0.015984  0.023474  0.015554  0.021331  0.015516   \n",
       "Hxcsection       0.007176  0.006151  0.010440  0.010923  0.015292  0.010470   \n",
       "Anteabruption    0.012481  0.016693  0.016737  0.012927  0.012210  0.007125   \n",
       "Antesteroid      0.010533  0.010102  0.004553  0.014561  0.013942  0.016047   \n",
       "CS_Elect         0.008647  0.012640  0.005741  0.009263  0.011854  0.011028   \n",
       "high_BMI         0.011835  0.006985  0.010587  0.006473  0.008253  0.010218   \n",
       "PostHBP          0.007945  0.011984  0.008135  0.005905  0.004306  0.004298   \n",
       "Marital          0.008516  0.011366  0.008105  0.005612  0.010291  0.004025   \n",
       "high_Gravidity   0.006746  0.008947  0.008529  0.008093  0.007101  0.005831   \n",
       "Ind_HTN          0.006619  0.007122  0.006650  0.004666  0.011715  0.003665   \n",
       "high_Age         0.005951  0.008356  0.006100  0.010186  0.005725  0.006276   \n",
       "AnteLGA          0.009621  0.005653  0.006348  0.003587  0.003183  0.004211   \n",
       "Preeclampsia     0.002235  0.005709  0.012370  0.002945  0.004577  0.009652   \n",
       "pre_diab         0.006421  0.003288  0.003572  0.009798  0.003406  0.003317   \n",
       "\n",
       "                        6         7         8         9  ...        16  \\\n",
       "HxnumCS          0.118182  0.124227  0.136038  0.133076  ...  0.117554   \n",
       "DMControl        0.115720  0.107632  0.131351  0.134597  ...  0.127274   \n",
       "prelaborCD       0.078310  0.083945  0.083431  0.083099  ...  0.073467   \n",
       "Hxanemia         0.063974  0.063962  0.071209  0.077653  ...  0.070108   \n",
       "Insurance        0.077509  0.051483  0.050590  0.053468  ...  0.062558   \n",
       "Education        0.053804  0.045803  0.058301  0.058819  ...  0.043925   \n",
       "Antefetdistress  0.038670  0.044961  0.049322  0.053025  ...  0.054418   \n",
       "Hostype          0.048192  0.047755  0.033990  0.019001  ...  0.052833   \n",
       "HospElectCS      0.035463  0.044117  0.031204  0.046316  ...  0.034431   \n",
       "momrace_new      0.036072  0.037309  0.033497  0.038388  ...  0.035240   \n",
       "HospElectInd     0.024866  0.035578  0.033085  0.027113  ...  0.025649   \n",
       "Admreason        0.026140  0.026372  0.025594  0.021829  ...  0.030343   \n",
       "Parity           0.019053  0.021015  0.017672  0.019945  ...  0.014918   \n",
       "CS_UScar         0.016271  0.022857  0.014446  0.018579  ...  0.014917   \n",
       "Anteanemia       0.012382  0.018787  0.028130  0.015171  ...  0.015501   \n",
       "uscar            0.025030  0.020438  0.017282  0.015370  ...  0.026595   \n",
       "Anteprevia       0.019028  0.015550  0.012696  0.017287  ...  0.020465   \n",
       "Hxcsection       0.009183  0.023906  0.010338  0.015272  ...  0.022396   \n",
       "Anteabruption    0.018034  0.010185  0.015047  0.015907  ...  0.012126   \n",
       "Antesteroid      0.006815  0.010583  0.014227  0.010016  ...  0.013859   \n",
       "CS_Elect         0.012774  0.014903  0.016145  0.010239  ...  0.013413   \n",
       "high_BMI         0.009253  0.012843  0.006902  0.008860  ...  0.008192   \n",
       "PostHBP          0.016635  0.011065  0.004950  0.005831  ...  0.008309   \n",
       "Marital          0.007118  0.006988  0.005885  0.006242  ...  0.011716   \n",
       "high_Gravidity   0.008261  0.009596  0.005843  0.007391  ...  0.004802   \n",
       "Ind_HTN          0.008532  0.008368  0.007795  0.005926  ...  0.009040   \n",
       "high_Age         0.006185  0.006542  0.005530  0.005670  ...  0.006980   \n",
       "AnteLGA          0.003596  0.005232  0.005094  0.005000  ...  0.005991   \n",
       "Preeclampsia     0.004553  0.002581  0.005089  0.006079  ...  0.006582   \n",
       "pre_diab         0.008808  0.004622  0.005378  0.005976  ...  0.004920   \n",
       "\n",
       "                       17        18        19        20        21        22  \\\n",
       "HxnumCS          0.118867  0.148099  0.119524  0.131439  0.118440  0.129595   \n",
       "DMControl        0.127296  0.109678  0.121699  0.117150  0.107422  0.124563   \n",
       "prelaborCD       0.074255  0.113419  0.083552  0.077906  0.087991  0.078412   \n",
       "Hxanemia         0.071376  0.055276  0.068422  0.074181  0.061394  0.067700   \n",
       "Insurance        0.058432  0.050307  0.065298  0.066693  0.063441  0.068996   \n",
       "Education        0.038333  0.046698  0.044227  0.058135  0.059249  0.043288   \n",
       "Antefetdistress  0.046300  0.050658  0.040868  0.054324  0.047956  0.055392   \n",
       "Hostype          0.047666  0.034587  0.046601  0.041094  0.046966  0.031296   \n",
       "HospElectCS      0.041250  0.034367  0.044504  0.032631  0.039233  0.044128   \n",
       "momrace_new      0.040718  0.034100  0.033412  0.036743  0.034666  0.029047   \n",
       "HospElectInd     0.028296  0.035505  0.030501  0.023608  0.026103  0.026841   \n",
       "Admreason        0.026714  0.018962  0.027129  0.022449  0.021328  0.022978   \n",
       "Parity           0.029499  0.022884  0.018982  0.018910  0.024037  0.030486   \n",
       "CS_UScar         0.019322  0.010157  0.022960  0.016558  0.022247  0.026559   \n",
       "Anteanemia       0.018923  0.021443  0.020672  0.017155  0.024777  0.022649   \n",
       "uscar            0.017691  0.013841  0.026194  0.009844  0.029606  0.025813   \n",
       "Anteprevia       0.015074  0.019875  0.019635  0.011501  0.010576  0.013183   \n",
       "Hxcsection       0.020338  0.013746  0.014165  0.021196  0.010532  0.009268   \n",
       "Anteabruption    0.012619  0.015502  0.015636  0.019710  0.017487  0.013452   \n",
       "Antesteroid      0.013588  0.015220  0.009759  0.008831  0.013446  0.011532   \n",
       "CS_Elect         0.009652  0.015362  0.010350  0.010217  0.009136  0.013634   \n",
       "high_BMI         0.007803  0.006645  0.007680  0.005169  0.013350  0.005965   \n",
       "PostHBP          0.005762  0.010889  0.007749  0.010896  0.008193  0.004870   \n",
       "Marital          0.008217  0.009418  0.007084  0.005820  0.007391  0.009461   \n",
       "high_Gravidity   0.007669  0.007421  0.007199  0.007931  0.006056  0.006698   \n",
       "Ind_HTN          0.006664  0.007786  0.007439  0.006014  0.009043  0.004589   \n",
       "high_Age         0.006363  0.004810  0.005866  0.005225  0.005373  0.003354   \n",
       "AnteLGA          0.006085  0.005045  0.007337  0.007341  0.006020  0.002750   \n",
       "Preeclampsia     0.002681  0.006928  0.003348  0.005124  0.004320  0.004767   \n",
       "pre_diab         0.001777  0.004466  0.005100  0.005347  0.005484  0.003658   \n",
       "\n",
       "                       23        24      mean  \n",
       "HxnumCS          0.129290  0.116968  0.128191  \n",
       "DMControl        0.115088  0.120292  0.120303  \n",
       "prelaborCD       0.082201  0.090533  0.085979  \n",
       "Hxanemia         0.068863  0.062430  0.067088  \n",
       "Insurance        0.068237  0.068611  0.062976  \n",
       "Education        0.049971  0.047959  0.049717  \n",
       "Antefetdistress  0.049469  0.030850  0.046927  \n",
       "Hostype          0.044349  0.051476  0.040027  \n",
       "HospElectCS      0.026120  0.041345  0.036438  \n",
       "momrace_new      0.040519  0.039586  0.035549  \n",
       "HospElectInd     0.030053  0.031262  0.028896  \n",
       "Admreason        0.025756  0.035964  0.024608  \n",
       "Parity           0.019845  0.021811  0.022413  \n",
       "CS_UScar         0.031331  0.027885  0.021044  \n",
       "Anteanemia       0.017734  0.015781  0.020151  \n",
       "uscar            0.019871  0.011321  0.018740  \n",
       "Anteprevia       0.013705  0.016614  0.016704  \n",
       "Hxcsection       0.011677  0.020707  0.015395  \n",
       "Anteabruption    0.011443  0.010923  0.013718  \n",
       "Antesteroid      0.015787  0.010744  0.012058  \n",
       "CS_Elect         0.012945  0.011126  0.010899  \n",
       "high_BMI         0.006184  0.008614  0.008491  \n",
       "PostHBP          0.004620  0.009620  0.007866  \n",
       "Marital          0.006842  0.008326  0.007855  \n",
       "high_Gravidity   0.004386  0.007131  0.007233  \n",
       "Ind_HTN          0.004004  0.006031  0.006566  \n",
       "high_Age         0.008222  0.005515  0.006193  \n",
       "AnteLGA          0.008878  0.002470  0.005242  \n",
       "Preeclampsia     0.006269  0.003290  0.005035  \n",
       "pre_diab         0.003785  0.007121  0.005002  \n",
       "\n",
       "[30 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_df['mean'] = feats_df.mean(axis=1)\n",
    "feats_df.sort_values(by='mean', inplace=True, ascending=False)\n",
    "feats_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
