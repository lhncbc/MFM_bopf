{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, recall_score, \\\n",
    "                            classification_report, roc_auc_score, precision_score, \\\n",
    "                            f1_score, matthews_corrcoef, average_precision_score, \\\n",
    "                            precision_recall_curve, auc, roc_curve\n",
    "from collections import Counter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(y_test, y_pred, X_test, clf):\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    prob1 = probs[:, 1]\n",
    "    stats_s = pd.Series(dtype='float')\n",
    "    stats_s['recall'] = recall_score(y_test, y_pred)\n",
    "    stats_s['prec'] = precision_score(y_test, y_pred)\n",
    "    stats_s['MCC'] = matthews_corrcoef(y_test, y_pred)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, prob1, pos_label=1)\n",
    "    stats_s['PR_AUC'] = auc(recall, precision)\n",
    "    stats_s['avg_prec'] = average_precision_score(y_test, prob1)\n",
    "    stats_s['roc_auc'] = roc_auc_score(y_test, prob1)\n",
    "\n",
    "    return stats_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "def sample_data(X, y, samp_type, samp_strat, seed=0):\n",
    "    if samp_type == 'over':\n",
    "        sampler = RandomOverSampler(sampling_strategy=samp_strat, random_state=seed)\n",
    "    elif samp_type == 'under':\n",
    "        sampler = RandomUnderSampler(sampling_strategy=samp_strat, random_state=seed)\n",
    "    else:\n",
    "        print(\"Invalid 'samp_type'\")\n",
    "        \n",
    "    # fit and apply the transform\n",
    "    X_res, y_res = sampler.fit_resample(X, y)\n",
    "    # summarize class distribution\n",
    "    #print(Counter(y_res))\n",
    "    #print(X_res.shape)\n",
    "    \n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapped  random statistics runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "def bootstrap_stat(X, y, clf, nsamples=100, under=False, samp_strat=1.0):\n",
    "    stats_df = pd.DataFrame()\n",
    "    for seed in range(nsamples):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=seed)\n",
    "        #print(f'In bstrap(): y_train.shape = {y_train.shape}; X_train.shape = {X_train.shape}')\n",
    "        #print(f'In bstrap(): np.bincount(y_train) = {np.bincount(y_train)}')\n",
    "\n",
    "        if under:\n",
    "            # Undersample the training data\n",
    "            #print('Undersampling')\n",
    "            X_res, y_res = sample_data(X_train, y_train, \"under\", samp_strat=samp_strat, seed=seed)\n",
    "        else:\n",
    "            #print('No Undersampling')\n",
    "            X_res, y_res = X, y # Not subsampled - for use with class_weight='balanced'\n",
    "            \n",
    "#        print(f'In kfold_cv: train_y.shape = {train_y.shape}')\n",
    "#        if sample_weights:\n",
    "#            weights = class_weight.compute_sample_weight('balanced', y=y_res)\n",
    "#            print(f'np.unique(weights): {np.unique(weights)}')\n",
    "#            clf.fit(X_res, y_res, sample_weight=weights)\n",
    "#        else:\n",
    "#            clf.fit(X_res, y_res)\n",
    "#            \n",
    "        clf.fit(X_res, y_res)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        stats_s = calc_stats(y_test, y_pred, X_test, clf)\n",
    "        if stats_df.empty:\n",
    "            stats_df = pd.DataFrame(stats_s)\n",
    "            stats_df = stats_df.T\n",
    "        else:\n",
    "            stats_df = stats_df.append(stats_s, ignore_index=True)\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = pd.read_csv('../../data/csl/CramerTheil/Cramer_PI_Tl_coeff_Union50.csv', index_col=0, header=None, delimiter='\\t')\n",
    "corr_vars = list(corr_df.index.values)\n",
    "len(corr_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/csl/CSL_tl_PI.csv', index_col=0)\n",
    "X = df.drop('trans_loss', axis=1, inplace=False)\n",
    "#X = X[corr_vars]\n",
    "y = df['trans_loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 7, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "CPU times: user 1h 3min 3s, sys: 5min 8s, total: 1h 8min 12s\n",
      "Wall time: 55min 11s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>prec</th>\n",
       "      <th>MCC</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.840799</td>\n",
       "      <td>0.130274</td>\n",
       "      <td>0.243443</td>\n",
       "      <td>0.177571</td>\n",
       "      <td>0.177815</td>\n",
       "      <td>0.813972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.128824</td>\n",
       "      <td>0.236686</td>\n",
       "      <td>0.179516</td>\n",
       "      <td>0.179790</td>\n",
       "      <td>0.813363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.832743</td>\n",
       "      <td>0.128762</td>\n",
       "      <td>0.238883</td>\n",
       "      <td>0.184744</td>\n",
       "      <td>0.185011</td>\n",
       "      <td>0.815107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821463</td>\n",
       "      <td>0.128123</td>\n",
       "      <td>0.235196</td>\n",
       "      <td>0.174318</td>\n",
       "      <td>0.174669</td>\n",
       "      <td>0.812075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830164</td>\n",
       "      <td>0.129656</td>\n",
       "      <td>0.239927</td>\n",
       "      <td>0.182402</td>\n",
       "      <td>0.182660</td>\n",
       "      <td>0.813307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.838543</td>\n",
       "      <td>0.128430</td>\n",
       "      <td>0.239580</td>\n",
       "      <td>0.176689</td>\n",
       "      <td>0.176959</td>\n",
       "      <td>0.813107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.829520</td>\n",
       "      <td>0.127996</td>\n",
       "      <td>0.236763</td>\n",
       "      <td>0.173261</td>\n",
       "      <td>0.173530</td>\n",
       "      <td>0.810570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.828553</td>\n",
       "      <td>0.127265</td>\n",
       "      <td>0.235205</td>\n",
       "      <td>0.180076</td>\n",
       "      <td>0.180424</td>\n",
       "      <td>0.814209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.830809</td>\n",
       "      <td>0.130883</td>\n",
       "      <td>0.242282</td>\n",
       "      <td>0.178981</td>\n",
       "      <td>0.179245</td>\n",
       "      <td>0.815282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.829452</td>\n",
       "      <td>0.128668</td>\n",
       "      <td>0.237973</td>\n",
       "      <td>0.177399</td>\n",
       "      <td>0.177673</td>\n",
       "      <td>0.812855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        recall      prec       MCC    PR_AUC  avg_prec   roc_auc\n",
       "0     0.840799  0.130274  0.243443  0.177571  0.177815  0.813972\n",
       "1     0.822430  0.128824  0.236686  0.179516  0.179790  0.813363\n",
       "2     0.832743  0.128762  0.238883  0.184744  0.185011  0.815107\n",
       "3     0.821463  0.128123  0.235196  0.174318  0.174669  0.812075\n",
       "4     0.830164  0.129656  0.239927  0.182402  0.182660  0.813307\n",
       "...        ...       ...       ...       ...       ...       ...\n",
       "996   0.838543  0.128430  0.239580  0.176689  0.176959  0.813107\n",
       "997   0.829520  0.127996  0.236763  0.173261  0.173530  0.810570\n",
       "998   0.828553  0.127265  0.235205  0.180076  0.180424  0.814209\n",
       "999   0.830809  0.130883  0.242282  0.178981  0.179245  0.815282\n",
       "mean  0.829452  0.128668  0.237973  0.177399  0.177673  0.812855\n",
       "\n",
       "[1001 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(C=0.1,solver=\"liblinear\",class_weight=\"balanced\",random_state=7)\n",
    "print(clf.get_params())\n",
    "stats_df = bootstrap_stat(X, y, clf, nsamples=1000, under=True, samp_strat=0.5)\n",
    "stats_df.loc['mean'] = stats_df.mean()\n",
    "#stats_df.loc['mean',:]\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:    mean = 0.8295; 95% CI = [0.8137 0.844 ]\n",
      "Precision: mean = 0.1287; 95% CI = [0.1267 0.1307]\n",
      "MCC:       mean = 0.2380; 95% CI = [0.2318 0.244 ]\n",
      "PR_AUC:    mean = 0.1774; 95% CI = [0.1692 0.1855]\n",
      "ROC_AUC:   mean = 0.8129; 95% CI = [0.8078 0.8178]\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall:    mean = {stats_df[\"recall\"][\"mean\"]:.4f}; 95% CI = {np.around(np.percentile(stats_df[\"recall\"], (2.5, 97.5)), 4)}')\n",
    "print(f'Precision: mean = {stats_df[\"prec\"][\"mean\"]:.4f}; 95% CI = {np.around(np.percentile(stats_df[\"prec\"], (2.5, 97.5)), 4)}')\n",
    "print(f'MCC:       mean = {stats_df[\"MCC\"][\"mean\"]:.4f}; 95% CI = {np.around(np.percentile(stats_df[\"MCC\"], (2.5, 97.5)), 4)}')\n",
    "print(f'PR_AUC:    mean = {stats_df[\"PR_AUC\"][\"mean\"]:.4f}; 95% CI = {np.around(np.percentile(stats_df[\"PR_AUC\"], (2.5, 97.5)), 4)}')\n",
    "print(f'ROC_AUC:   mean = {stats_df[\"roc_auc\"][\"mean\"]:.4f}; 95% CI = {np.around(np.percentile(stats_df[\"roc_auc\"], (2.5, 97.5)), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
