{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plthttp://localhost:8888/notebooks/MFMDatasets/MFM_bopf/src/site_compare/HighEBL-Site47-GB-CV.ipynb#\n",
    "#import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, \\\n",
    "                            accuracy_score, f1_score, average_precision_score, \\\n",
    "                            fbeta_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/csl/Sites/CSL_he_PI_s47.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fb0ac9ba8332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcsl_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/csl/Sites/CSL_he_PI_s47.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsl_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'high_EBL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Sitenum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsl_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'high_EBL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/csl/Sites/CSL_he_PI_s47.csv'"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "# NOTE - Site 47 fails because the EBLoss data is MISSING.\n",
    "#########################################################\n",
    "csl_df = pd.read_csv('../../data/csl/Sites/CSL_he_PI_s47.csv', index_col=0)\n",
    "X = csl_df.drop(['high_EBL','Sitenum'], axis=1, inplace=False)\n",
    "y = csl_df['high_EBL'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=7)\n",
    "X_train                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Exploratory Data Analysis</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(csl_df['new_age'],csl_df['high_EBL'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(csl_df['new_age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(csl_df['new_BMI'],csl_df['high_EBL'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(csl_df['new_BMI'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Modelling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Modelling Using Undersampling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `imblearn`'s RandomUnderSampler to undersample from the majority class so that they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomUnderSampler(sampling_strategy=1.0, random_state=7)\n",
    "X_rus, y_rus = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Try with no undersampling\n",
    "#X_rus, y_rus = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_rus.shape)\n",
    "print(y_rus.shape)\n",
    "print(np.bincount(y_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Basic Gradient Boosting</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import class_weight\n",
    "gb_rus = GradientBoostingClassifier()   # If not undersampling\n",
    "gb_rus.fit(X_rus, y_rus)\n",
    "print(gb_rus.get_params())\n",
    "y_pred = gb_rus.predict(X_test)\n",
    "probs = gb_rus.predict_proba(X_test)\n",
    "prob1 = probs[:, 1]  # Only positives\n",
    "precision, recall, pr_thresh = precision_recall_curve(y_test, prob1)\n",
    "print(confusion_matrix(y_pred=y_pred, y_true=y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'ROC AUC prob1: {roc_auc_score(y_test, prob1)}')\n",
    "print(f'MCC: {matthews_corrcoef(y_test, y_pred)}')\n",
    "print(f'F2: {fbeta_score(y_test, y_pred, beta=2.0, average=None)[1]}')\n",
    "print(f'PR_AUC: {auc(recall, precision)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Not undersampled\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import class_weight\n",
    "gb_weight = GradientBoostingClassifier()  \n",
    "weights = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "gb_weight.fit(X_train, y_train, sample_weight=weights)\n",
    "print(gb_weight.get_params())\n",
    "y_pred = gb_weight.predict(X_test)\n",
    "probs = gb_weight.predict_proba(X_test)\n",
    "prob1 = probs[:, 1]  # Only positives\n",
    "precision, recall, pr_thresh = precision_recall_curve(y_test, prob1)\n",
    "print(confusion_matrix(y_pred=y_pred, y_true=y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'ROC AUC prob1: {roc_auc_score(y_test, prob1)}')\n",
    "print(f'MCC: {matthews_corrcoef(y_test, y_pred)}')\n",
    "print(f'F2: {fbeta_score(y_test, y_pred, beta=2.0, average=None)[1]}')\n",
    "print(f'PR_AUC: {auc(recall, precision)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Hyperparameter Tuning with Cross Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def create_model(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    subsample = trial.suggest_float('subsample', 0.8, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth',3,20)\n",
    "    max_features = trial.suggest_int('max_features',10,20)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate',0.08,0.2)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf',1,50)\n",
    "    model = GradientBoostingClassifier(n_estimators=n_estimators, subsample=subsample, \n",
    "                           max_depth=max_depth, learning_rate=learning_rate, \n",
    "                           min_samples_leaf=min_samples_leaf)\n",
    "#    model = GradientBoostingClassifier(n_estimators=n_estimators, subsample=subsample, \n",
    "#                           learning_rate=learning_rate, \n",
    "#                           min_samples_leaf=min_samples_leaf)\n",
    "#    model = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate) \n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    mcc_list = []\n",
    "    roc_list = []\n",
    "    pr_list = []\n",
    "    f2_list = []\n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=11)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train_c, X_test_c = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_c, y_test_c = y[train_idx], y[test_idx]\n",
    "        sampler = RandomUnderSampler(sampling_strategy=1.0, random_state=7)\n",
    "        X_res, y_res = sampler.fit_resample(X_train_c, y_train_c)\n",
    "\n",
    "#        weights = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "#        model.fit(X_train, y_train, sample_weight=weights)\n",
    "        model.fit(X_res, y_res)\n",
    "        y_pred = model.predict(X_test_c)\n",
    "        probs = model.predict_proba(X_test_c)\n",
    "        prob1 = probs[:, 1]  # Only positives\n",
    "        precision, recall, pr_thresh = precision_recall_curve(y_test_c, prob1)\n",
    "        roc = roc_auc_score(y_test_c, prob1)\n",
    "        roc_list.append(roc)\n",
    "        mcc = matthews_corrcoef(y_test_c, y_pred)  # MWB\n",
    "        mcc_list.append(mcc)\n",
    "        f2 = fbeta_score(y_test_c, y_pred, beta=2.0, average=None)[1]\n",
    "        pr_auc = auc(recall, precision)\n",
    "        pr_list.append(pr_auc)\n",
    "        avg_precision = average_precision_score(y_test_c, prob1)\n",
    "#        print(f'ROC: {roc}')\n",
    "#        print(f'PR_AUC: {pr_auc}')\n",
    "#        print(f'avg_prec: {avg_precision}')\n",
    "        \n",
    "    print(f'MCC: {mcc_list}')\n",
    "    print(f'ROC: {roc_list}')\n",
    "    print(f'PR_AUC: {pr_list}')\n",
    "    return np.mean(mcc_list)\n",
    "\n",
    "sampler = TPESampler(seed=7)\n",
    "study = optuna.create_study(sampler=sampler,direction='maximize')\n",
    "#study.optimize(objective,n_trials=60)\n",
    "study.optimize(objective,n_trials=25)\n",
    "#study.optimize(objective,n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.best_trial\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gb_params = study.best_params\n",
    "#gb_params['random_state'] = 42\n",
    "gb = GradientBoostingClassifier(**gb_params)\n",
    "gb.fit(X_rus, y_rus)\n",
    "y_pred = gb.predict(X_test)\n",
    "probs = gb.predict_proba(X_test)\n",
    "prob1 = probs[:, 1]  # Only positives\n",
    "precision, recall, pr_thresh = precision_recall_curve(y_test, prob1)\n",
    "print(confusion_matrix(y_pred=y_pred, y_true=y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'ROC AUC prob1: {roc_auc_score(y_test, prob1)}')\n",
    "print(f'MCC: {matthews_corrcoef(y_test, y_pred)}')\n",
    "print(f'F2: {fbeta_score(y_test, y_pred, beta=2.0, average=None)[1]}')\n",
    "print(f'PR_AUC: {auc(recall, precision)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gb_params = study.best_params\n",
    "gb_params['random_state'] = 42\n",
    "gb_weight = GradientBoostingClassifier(**gb_params)\n",
    "weights = class_weight.compute_sample_weight('balanced', y=y_train)\n",
    "gb_weight.fit(X_train, y_train, sample_weight=weights)\n",
    "y_pred = gb_weight.predict(X_test)\n",
    "probs = gb_weight.predict_proba(X_test)\n",
    "prob1 = probs[:, 1]  # Only positives\n",
    "precision, recall, pr_thresh = precision_recall_curve(y_test, prob1)\n",
    "print(confusion_matrix(y_pred=y_pred, y_true=y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'ROC AUC prob1: {roc_auc_score(y_test, prob1)}')\n",
    "print(f'MCC: {matthews_corrcoef(y_test, y_pred)}')\n",
    "print(f'F2: {fbeta_score(y_test, y_pred, beta=2.0, average=None)[1]}')\n",
    "print(f'PR_AUC: {auc(recall, precision)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Sitenum - 5\n",
    "coeffs_wgt = pd.Series(data=gb_weight.feature_importances_,\n",
    "                   index=X_test.columns.values).sort_values(ascending=False)\n",
    "coeffs_wgt[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "x_labels = coeffs_wgt.index.values[0:25]\n",
    "print(x_labels)\n",
    "fig, ax = plt.subplots(1,1)  # Create a figure and an axes.\n",
    "ax.set_title('Top Predictors: All Sites combined; target: High_EBLoss, vars: PI')\n",
    "ax.bar(x_labels, coeffs_wgt.values[0:25])\n",
    "ax.set_ylabel('Coeff')\n",
    "ax.set_xlabel('Variable')\n",
    "plt.draw()\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=16)\n",
    "#plt.xlim(1,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Sitenum - 5\n",
    "coeffs = pd.Series(data=gb.feature_importances_,\n",
    "                   index=X_test.columns.values).sort_values(ascending=False)\n",
    "coeffs[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "sns.heatmap(np.round(confusion_matrix(y_test, y_pred, normalize='true'), decimals=2), cmap='magma', annot=True, fmt='g') # 25\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params # 5 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "plotly_config = {\"staticPlot\": True}\n",
    "\n",
    "fig = plot_optimization_history(study)\n",
    "fig.show(config=plotly_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "fig = plot_param_importances(study)\n",
    "fig.show(config=plotly_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([0.3149689279176914, 0.31449457458602254, 0.31066798538596907, 0.3219519143488398])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Thanks and make sure to learn!</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
